{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd802481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaconv\n",
      "  Using cached kaconv-0.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting torch>=2.3.0 (from kaconv)\n",
      "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "INFO: pip is looking at multiple versions of kaconv to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision>=1.18.0 (from kaconv) (from versions: 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision>=1.18.0\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13bf736-4203-4feb-ba8a-bef4dbd07f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45a12bf-8706-4200-b677-891dde8a0919",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaconv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import FastKANConvLayer and ConvKAN classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkaconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvkan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvKAN\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkaconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkaconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastKANConvLayer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2d, BatchNorm2d\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaconv'"
     ]
    }
   ],
   "source": [
    "# Import FastKANConvLayer and ConvKAN classes\n",
    "from kaconv.convkan import ConvKAN\n",
    "from kaconv.kaconv import FastKANConvLayer\n",
    "from torch.nn import Conv2d, BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e76bd0-3942-437e-beba-ab6a37218edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # Ensures deterministic behavior on CPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f268ab83-5cb3-475e-bec7-6f057507b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_KAN_Model(nn.Module):\n",
    "    def __init__(self, kan_type=\"RBF\"):\n",
    "        super(CIFAR10_KAN_Model, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            FastKANConvLayer(3, 32, padding=1, kernel_size=3, stride=1, kan_type=kan_type),\n",
    "            BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            FastKANConvLayer(32, 64, padding=1, kernel_size=3, stride=2, kan_type=kan_type),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            FastKANConvLayer(64, 128, padding=1, kernel_size=3, stride=2, kan_type=kan_type),\n",
    "            BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8837a22f-023a-4ecf-9750-c42429ed58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training function\n",
    "def train_model():\n",
    "    # Set seed\n",
    "    set_seed(44)\n",
    "\n",
    "    # Check device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Model initialization\n",
    "    model = CIFAR10_KAN_Model(kan_type=\"RBF\").to(device)\n",
    "\n",
    "    # Define transformations and load dataset\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 150, eta_min=0.0001)\n",
    "\n",
    "    # Training loop\n",
    "    best_acc = 0\n",
    "    for epoch in tqdm(range(150), desc=\"Training\"):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_hat = model(x)\n",
    "                _, predicted = torch.max(y_hat, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (predicted == y).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "\n",
    "        print(\n",
    "            f'Epoch [{epoch + 1}/150], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {acc:.2f}%, Best Accuracy: {best_acc:.2f}%')\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Training complete. Best accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c282c-0fdd-4c66-998e-1969811a1679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                | 0/150 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8dceb-1997-41ed-8cd5-b7a4242acf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
