{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pykan Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pykan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KANs on Univariate Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Number Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from kan import KAN\n",
    "from kan.utils import create_dataset, ex_round\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('datasets/numsquares.csv')\n",
    "x = torch.tensor(df[['number']].values, dtype=torch.float32)\n",
    "y = torch.tensor(df[['square']].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Step 2: Prepare the dataset\n",
    "dataset = {\n",
    "    'train_input': x,\n",
    "    'train_label': y,\n",
    "    'test_input': x,  # Using the same data for testing, for simplicity\n",
    "    'test_label': y\n",
    "}\n",
    "\n",
    "# Step 3: Initialize the KAN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KAN(width=[1, 5, 1], grid=3, k=3, seed=42, device=device)\n",
    "\n",
    "# Step 4: Plot initial KAN state (Optional)\n",
    "model(dataset['train_input'])\n",
    "model.plot()\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(dataset, opt=\"LBFGS\", steps=100, lamb=0.001)\n",
    "\n",
    "# Step 6: Plot trained KAN state (Optional)\n",
    "model.plot()\n",
    "\n",
    "# Step 7: Extract and print the symbolic formula\n",
    "symbolic_formula = ex_round(model.symbolic_formula()[0][0], 4)\n",
    "print(\"Learned symbolic formula:\", symbolic_formula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted square of 8 is approximately 64.00260162353516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.00260162353516"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_square(number):\n",
    "    # Convert the input to a tensor and ensure it's on the same device\n",
    "    input_tensor = torch.tensor([[number]], dtype=torch.float32).to(device)\n",
    "\n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():  # No need for gradients during inference\n",
    "        output_tensor = model(input_tensor)\n",
    "\n",
    "    # Extract the predicted value and print it\n",
    "    predicted_square = output_tensor.item()\n",
    "    print(f\"The predicted square of {number} is approximately {predicted_square}\")\n",
    "    return predicted_square\n",
    "\n",
    "\n",
    "predict_square(int(input(\"Input Number:\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Univariate Time Series (Daily Minimum Temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 7.50e-02 | test_loss: 1.02e-01 | reg: 1.63e+01 | : 100%|â–ˆ| 100/100 [00:38<00:00,  2.57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "time_series_data = pd.read_csv('datasets/dailymintemp.csv', parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "# Feature Engineering\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "# Convert labels to Float type\n",
    "train_labels = torch.tensor(train_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Normalize labels and window values\n",
    "norm_max = train_labels.max()\n",
    "train_labels /= norm_max\n",
    "test_labels /= norm_max\n",
    "for window_column in window_columns:\n",
    "    selected_data[window_column] /= norm_max.item()\n",
    "\n",
    "input_columns = BASE_INPUT_COLUMNS + window_columns\n",
    "train_input = torch.tensor(np.array([train_raw[in_col].values for in_col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "test_input = torch.tensor(np.array([test_raw[in_col].values for in_col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "# Training model with sliding window data\n",
    "model = kan.KAN(width=[len(input_columns), 3, 3, 1], grid=10, k=3, seed=0)\n",
    "model.fit({'train_input': train_input, 'train_label': train_labels, 'test_input': test_input, 'test_label': test_labels}, opt=\"LBFGS\", steps=100)\n",
    "\n",
    "# Save the model for inference\n",
    "torch.save(model.state_dict(), 'trained_kan_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Array: [0.08333333333333333, 0.16129032258064516, 0.9772727272727273, 0.8636363636363636, 0.8409090909090909]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data similar to your original dataset\n",
    "data = {\n",
    "    \"Date\": pd.date_range(start=\"2022-01-01\", periods=10, freq=\"D\"),\n",
    "    \"Daily minimum temperatures\": [20.0, 18.5, 19.0, 21.5, 20.0, 17.5, 18.0, 20.5, 22.0, 19.5]\n",
    "}\n",
    "time_series_data = pd.DataFrame(data)\n",
    "\n",
    "# Normalize columns\n",
    "time_series_data[\"month normalized\"] = time_series_data[\"Date\"].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[\"Date\"].dt.day / time_series_data[\"Date\"].dt.days_in_month\n",
    "\n",
    "# Add past temperatures (recent values)\n",
    "window_len = 3\n",
    "for i in range(1, window_len + 1):\n",
    "    time_series_data[f\"old val -{i}\"] = time_series_data[\"Daily minimum temperatures\"].shift(i)\n",
    "\n",
    "# Define a function to get the normalized input array for a specific date\n",
    "def get_normalized_array(date, df):\n",
    "    # Filter for the specific date\n",
    "    row = df[df[\"Date\"] == date].iloc[0]\n",
    "\n",
    "    # Normalize recent temperatures by the maximum temperature in the dataset (for consistency)\n",
    "    norm_max = df[\"Daily minimum temperatures\"].max()\n",
    "\n",
    "    # Prepare the array\n",
    "    normalized_array = [\n",
    "        row[\"month normalized\"],\n",
    "        row[\"day normalized\"],\n",
    "        row[f\"old val -1\"] / norm_max if pd.notna(row[f\"old val -1\"]) else None,\n",
    "        row[f\"old val -2\"] / norm_max if pd.notna(row[f\"old val -2\"]) else None,\n",
    "        row[f\"old val -3\"] / norm_max if pd.notna(row[f\"old val -3\"]) else None\n",
    "    ]\n",
    "    \n",
    "    return normalized_array\n",
    "\n",
    "# Example usage\n",
    "date_input = pd.Timestamp(\"2022-01-05\")\n",
    "normalized_array = get_normalized_array(date_input, time_series_data)\n",
    "print(\"Normalized Array:\", normalized_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Predicted Daily Minimum Temperature: 8.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Define model architecture (ensure it matches the architecture used during training)\n",
    "model = kan.KAN(width=[5, 3, 3, 1], grid=10, k=3, seed=0)  # Adjust `width` based on the input configuration during training\n",
    "\n",
    "# Load the state dictionary from the saved file\n",
    "model.load_state_dict(torch.load('trained_kan_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Prediction function\n",
    "def predict_daily_min_temp(input_data, norm_max):\n",
    "    # Convert the input data to a tensor with float32 dtype\n",
    "    input_tensor = torch.tensor([input_data], dtype=torch.float32)\n",
    "    \n",
    "    # Make prediction without computing gradients\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor)\n",
    "    \n",
    "    # Denormalize the output to get the actual temperature value\n",
    "    predicted_temp = output_tensor.item() * norm_max\n",
    "    return predicted_temp\n",
    "\n",
    "# Example normalized input for prediction\n",
    "# Format: [month normalized, day normalized, old val -1, old val -2, old val -3]\n",
    "sample_input = [0.5, 0.15, 0.7, 0.65, 0.6]  # Replace with actual input values\n",
    "norm_max = 20.0  # Replace with the actual max value used for label normalization during training\n",
    "\n",
    "# Run inference\n",
    "predicted_temp = predict_daily_min_temp(sample_input, norm_max)\n",
    "print(f\"Predicted Daily Minimum Temperature: {predicted_temp:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KAN on Multivariate Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Irrigation System (small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 9.87e-02 | test_loss: 4.56e-02 | reg: 1.46e+01 | : 100%|â–ˆ| 100/100 [00:06<00:00, 14.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Training completed and model saved as 'trained_irrigation_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation1.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"moisture\", \"temp\"]\n",
    "TARGET = \"pump\"\n",
    "\n",
    "# Split the data into inputs and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the model\n",
    "model = kan.KAN(width=[2, 3, 3, 1], grid=5, k=3, seed=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit({'train_input': train_X, 'train_label': train_y, 'test_input': test_X, 'test_label': test_y},\n",
    "          opt=\"LBFGS\", steps=100)\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_irrigation_model.pth')\n",
    "print(\"Training completed and model saved as 'trained_irrigation_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load the model architecture and state dictionary\n",
    "model = kan.KAN(width=[2, 3, 3, 1], grid=5, k=3, seed=0)\n",
    "model.load_state_dict(torch.load('trained_irrigation_model.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define a function for prediction\n",
    "def predict_pump(moisture, temp):\n",
    "    # Convert input to tensor\n",
    "    input_tensor = torch.tensor([[moisture, temp]], dtype=torch.float32)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    \n",
    "    # Interpret output as ON or OFF\n",
    "    pump_status = \"OFF\" if output.item() >= 0.5 else \"ON\"\n",
    "    return pump_status\n",
    "\n",
    "# Request user input\n",
    "try:\n",
    "    moisture = float(input(\"Enter soil moisture level: \"))\n",
    "    temp = float(input(\"Enter temperature: \"))\n",
    "    result = predict_pump(moisture, temp)\n",
    "    print(f\"The pump should be: {result}\")\n",
    "except ValueError:\n",
    "    print(\"Please enter valid numerical values for moisture and temperature.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Irrigation System (Large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"Rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \"Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the model\n",
    "model = kan.KAN(width=[len(FEATURES), 4, 4, 1], grid=5, k=3, seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit({'train_input': train_X, 'train_label': train_y, 'test_input': test_X, 'test_label': test_y},\n",
    "          opt=\"LBFGS\", steps=100)\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_irrigation_model.pth')\n",
    "print(\"Training completed and model saved as 'trained_irrigation_model.pth'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
