{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pykan Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pykan\n",
    "%pip install torchprofile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KANs on Univariate Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Number Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.78e+00 | test_loss: 5.78e+00 | reg: 1.28e+01 | :   0%| | 2/500 [00:00<00:35, 13.92it"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.49e+00 | test_loss: 5.49e+00 | reg: 4.32e+01 | : 100%|â–ˆ| 500/500 [00:11<00:00, 41.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Learned symbolic formula: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from kan import KAN\n",
    "from kan.utils import create_dataset, ex_round\n",
    "\n",
    "df = pd.read_csv('datasets/numsquares.csv')\n",
    "x = torch.tensor(df[['number']].values, dtype=torch.float32)\n",
    "y = torch.tensor(df[['square']].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "dataset = {\n",
    "    'train_input': x,\n",
    "    'train_label': y,\n",
    "    'test_input': x,  \n",
    "    'test_label': y\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KAN(width=[1, 1, 1], grid=1, k=1, seed=0, device=device)\n",
    "\n",
    "model(dataset['train_input'])\n",
    "model.plot()\n",
    "\n",
    "model.fit(dataset, opt=\"LBFGS\", steps=500, lamb=0.001)\n",
    "\n",
    "model.plot()\n",
    "\n",
    "symbolic_formula = ex_round(model.symbolic_formula()[0][0], 4)\n",
    "print(\"Learned symbolic formula:\", symbolic_formula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted square of 8 is approximately 63.323089599609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.323089599609375"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_square(number):\n",
    "    input_tensor = torch.tensor([[number]], dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        output_tensor = model(input_tensor)\n",
    "\n",
    "    predicted_square = output_tensor.item()\n",
    "    print(f\"The predicted square of {number} is approximately {predicted_square}\")\n",
    "    return predicted_square\n",
    "\n",
    "\n",
    "predict_square(int(input(\"Input Number:\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Estimated FLOPs for one forward pass: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::silu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unsqueeze\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::ge\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::nan_to_num\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from kan import KAN\n",
    "import torchprofile\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define and initialize the KAN model\n",
    "model = KAN(width=[1, 1, 1], grid=1, k=1, seed=0, device=device)\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Prepare a sample input tensor\n",
    "input_tensor = torch.tensor([[2]], dtype=torch.float32).to(device)  # Single input value\n",
    "\n",
    "# Calculate FLOPs using torchprofile\n",
    "with torch.no_grad():\n",
    "    flops = torchprofile.profile_macs(model, input_tensor)  # Get MACs as an estimate for FLOPs\n",
    "\n",
    "print(f\"Estimated FLOPs for one forward pass: {flops}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated FLOPs for one forward pass: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchprofile\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define a simple MLP with the same structure as the KAN model: [1, 1, 1]\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)\n",
    "        self.fc2 = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize and set the model to the specified device and evaluation mode\n",
    "model = SimpleMLP().to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare a sample input tensor\n",
    "input_tensor = torch.tensor([[2]], dtype=torch.float32).to(device)  # Single input value\n",
    "\n",
    "# Calculate FLOPs using torchprofile\n",
    "with torch.no_grad():\n",
    "    flops = torchprofile.profile_macs(model, input_tensor)  # Get MACs as an estimate for FLOPs\n",
    "\n",
    "print(f\"Estimated FLOPs for one forward pass: {flops}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Univariate Time Series (Daily Minimum Temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementation with KAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 7.50e-02 | test_loss: 1.02e-01 | reg: 1.63e+01 | : 100%|â–ˆ| 100/100 [00:38<00:00,  2.57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "time_series_data = pd.read_csv('datasets/dailymintemp.csv', parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "train_labels = torch.tensor(train_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "norm_max = train_labels.max()\n",
    "train_labels /= norm_max\n",
    "test_labels /= norm_max\n",
    "for window_column in window_columns:\n",
    "    selected_data[window_column] /= norm_max.item()\n",
    "\n",
    "input_columns = BASE_INPUT_COLUMNS + window_columns\n",
    "train_input = torch.tensor(np.array([train_raw[in_col].values for in_col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "test_input = torch.tensor(np.array([test_raw[in_col].values for in_col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "model = kan.KAN(width=[len(input_columns), 3, 3, 1], grid=10, k=3, seed=0)\n",
    "model.fit({'train_input': train_input, 'train_label': train_labels, 'test_input': test_input, 'test_label': test_labels}, opt=\"LBFGS\", steps=100)\n",
    "\n",
    "torch.save(model.state_dict(), 'trained_kan_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Array: [0.08333333333333333, 0.16129032258064516, 0.9772727272727273, 0.8636363636363636, 0.8409090909090909]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"Date\": pd.date_range(start=\"2022-01-01\", periods=10, freq=\"D\"),\n",
    "    \"Daily minimum temperatures\": [20.0, 18.5, 19.0, 21.5, 20.0, 17.5, 18.0, 20.5, 22.0, 19.5]\n",
    "}\n",
    "time_series_data = pd.DataFrame(data)\n",
    "\n",
    "time_series_data[\"month normalized\"] = time_series_data[\"Date\"].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[\"Date\"].dt.day / time_series_data[\"Date\"].dt.days_in_month\n",
    "\n",
    "window_len = 3\n",
    "for i in range(1, window_len + 1):\n",
    "    time_series_data[f\"old val -{i}\"] = time_series_data[\"Daily minimum temperatures\"].shift(i)\n",
    "\n",
    "def get_normalized_array(date, df):\n",
    "    row = df[df[\"Date\"] == date].iloc[0]\n",
    "\n",
    "    norm_max = df[\"Daily minimum temperatures\"].max()\n",
    "\n",
    "    normalized_array = [\n",
    "        row[\"month normalized\"],\n",
    "        row[\"day normalized\"],\n",
    "        row[f\"old val -1\"] / norm_max if pd.notna(row[f\"old val -1\"]) else None,\n",
    "        row[f\"old val -2\"] / norm_max if pd.notna(row[f\"old val -2\"]) else None,\n",
    "        row[f\"old val -3\"] / norm_max if pd.notna(row[f\"old val -3\"]) else None\n",
    "    ]\n",
    "    \n",
    "    return normalized_array\n",
    "\n",
    "date_input = pd.Timestamp(\"2022-01-05\")\n",
    "normalized_array = get_normalized_array(date_input, time_series_data)\n",
    "print(\"Normalized Array:\", normalized_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Predicted Daily Minimum Temperature: 8.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import kan\n",
    "\n",
    "model = kan.KAN(width=[5, 3, 3, 1], grid=10, k=3, seed=0)  # Adjust `width` based on the input configuration during training\n",
    "\n",
    "model.load_state_dict(torch.load('trained_kan_model.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def predict_daily_min_temp(input_data, norm_max):\n",
    "    input_tensor = torch.tensor([input_data], dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor)\n",
    "    \n",
    "    predicted_temp = output_tensor.item() * norm_max\n",
    "    return predicted_temp\n",
    "\n",
    "sample_input = [0.5, 0.15, 0.7, 0.65, 0.6]  \n",
    "norm_max = 20.0  \n",
    "\n",
    "predicted_temp = predict_daily_min_temp(sample_input, norm_max)\n",
    "print(f\"Predicted Daily Minimum Temperature: {predicted_temp:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Mean Absolute Error (MAE): 53.3042\n",
      "Root Mean Squared Error (RMSE): 56.3500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "data_file = 'datasets/dailymintemp.csv'\n",
    "time_series_data = pd.read_csv(data_file, parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "norm_max = test_labels.max()\n",
    "test_labels /= norm_max\n",
    "test_input = torch.tensor(np.array([test_raw[col].values for col in BASE_INPUT_COLUMNS + window_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "model = kan.KAN(width=[len(BASE_INPUT_COLUMNS + window_columns), 3, 3, 1], grid=10, k=3, seed=0)\n",
    "model.load_state_dict(torch.load('trained_kan_model.pth'))\n",
    "model.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_input) * norm_max  \n",
    "    test_labels = test_labels * norm_max  \n",
    "\n",
    "predictions = predictions.numpy().squeeze()\n",
    "test_labels = test_labels.numpy().squeeze()\n",
    "\n",
    "mae = mean_absolute_error(test_labels, predictions)\n",
    "rmse = mean_squared_error(test_labels, predictions, squared=False)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated FLOPs for KAN model inference: 54\n"
     ]
    }
   ],
   "source": [
    "def calculate_kan_inference_flops(width):\n",
    "    total_flops = 0\n",
    "    for i in range(len(width) - 1):\n",
    "        input_size = width[i]\n",
    "        output_size = width[i + 1]\n",
    "        layer_flops = 2 * input_size * output_size  \n",
    "        total_flops += layer_flops\n",
    "    return total_flops\n",
    "\n",
    "kan_width = [5, 3, 3, 1]  \n",
    "inference_flops = calculate_kan_inference_flops(kan_width)\n",
    "print(f\"Estimated FLOPs for KAN model inference: {inference_flops}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementation with MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0219\n",
      "Epoch [20/100], Loss: 0.0208\n",
      "Epoch [30/100], Loss: 0.0202\n",
      "Epoch [40/100], Loss: 0.0195\n",
      "Epoch [50/100], Loss: 0.0186\n",
      "Epoch [60/100], Loss: 0.0176\n",
      "Epoch [70/100], Loss: 0.0165\n",
      "Epoch [80/100], Loss: 0.0154\n",
      "Epoch [90/100], Loss: 0.0145\n",
      "Epoch [100/100], Loss: 0.0137\n",
      "Training completed and model saved as 'trained_mlp_univariate_model.pth'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "time_series_data = pd.read_csv('datasets/dailymintemp.csv', parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "train_labels = torch.tensor(train_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "norm_max = train_labels.max()\n",
    "train_labels /= norm_max\n",
    "test_labels /= norm_max\n",
    "for window_column in window_columns:\n",
    "    selected_data[window_column] /= norm_max.item()\n",
    "\n",
    "input_columns = BASE_INPUT_COLUMNS + window_columns\n",
    "train_input = torch.tensor(np.array([train_raw[col].values for col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "test_input = torch.tensor(np.array([test_raw[col].values for col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 3)\n",
    "        self.hidden2 = nn.Linear(3, 3)\n",
    "        self.output = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(input_size=len(input_columns))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    outputs = model(train_input)\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'trained_mlp_univariate_model.pth')\n",
    "print(\"Training completed and model saved as 'trained_mlp_univariate_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 3)\n",
    "        self.hidden2 = nn.Linear(3, 3)\n",
    "        self.output = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "input_size = 5  \n",
    "model = MLP(input_size=input_size)\n",
    "model.load_state_dict(torch.load('trained_mlp_univariate_model.pth'))\n",
    "model.eval()  \n",
    "def make_prediction(month_norm, day_norm, old_val1, old_val2, old_val3, norm_max):\n",
    "    input_tensor = torch.tensor([[month_norm, day_norm, old_val1, old_val2, old_val3]], dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor) * norm_max \n",
    "    return prediction.item()\n",
    "\n",
    "print(\"Enter normalized values for prediction:\")\n",
    "month_norm = float(input(\"Month normalized (0-1): \"))\n",
    "day_norm = float(input(\"Day normalized (0-1): \"))\n",
    "old_val1 = float(input(\"Previous temperature (normalized): \"))\n",
    "old_val2 = float(input(\"Temperature 2 days ago (normalized): \"))\n",
    "old_val3 = float(input(\"Temperature 3 days ago (normalized): \"))\n",
    "\n",
    "norm_max = 20.0  \n",
    "\n",
    "predicted_temp = make_prediction(month_norm, day_norm, old_val1, old_val2, old_val3, norm_max)\n",
    "print(f\"Predicted Daily Minimum Temperature: {predicted_temp:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Check (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 92.0017\n",
      "Root Mean Squared Error (RMSE): 96.5915\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 3)\n",
    "        self.hidden2 = nn.Linear(3, 3)\n",
    "        self.output = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "data_file = 'datasets/dailymintemp.csv'\n",
    "time_series_data = pd.read_csv(data_file, parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "norm_max = test_labels.max()\n",
    "test_labels /= norm_max\n",
    "test_input = torch.tensor(np.array([test_raw[col].values for col in BASE_INPUT_COLUMNS + window_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "model = MLP(input_size=len(BASE_INPUT_COLUMNS + window_columns))\n",
    "model.load_state_dict(torch.load('trained_mlp_univariate_model.pth'))\n",
    "model.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_input) * norm_max  \n",
    "    test_labels = test_labels * norm_max  \n",
    "\n",
    "predictions = predictions.numpy().squeeze()\n",
    "test_labels = test_labels.numpy().squeeze()\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(test_labels, predictions)\n",
    "rmse = mean_squared_error(test_labels, predictions, squared=False)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  34, 100.000% Params, 34.0 Mac, 100.000% MACs, \n",
      "  (hidden1): Linear(18, 52.941% Params, 18.0 Mac, 52.941% MACs, in_features=5, out_features=3, bias=True)\n",
      "  (hidden2): Linear(12, 35.294% Params, 12.0 Mac, 35.294% MACs, in_features=3, out_features=3, bias=True)\n",
      "  (output): Linear(4, 11.765% Params, 4.0 Mac, 11.765% MACs, in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "Estimated FLOPs for inference with MLP model: 34 Mac\n",
      "Total parameters in the model: 34\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "# Define the MLP model class (same as in training and inference)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 3)\n",
    "        self.hidden2 = nn.Linear(3, 3)\n",
    "        self.output = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Load the trained model\n",
    "input_size = 5  # Adjust according to the input dimensions (month norm, day norm, and 3 previous values)\n",
    "model = MLP(input_size=input_size)\n",
    "model.load_state_dict(torch.load('trained_mlp_univariate_model.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Use ptflops to calculate FLOPs for a single forward pass (inference)\n",
    "with torch.no_grad():\n",
    "    flops, params = get_model_complexity_info(model, (input_size,), as_strings=True, print_per_layer_stat=True)\n",
    "    print(f\"Estimated FLOPs for inference with MLP model: {flops}\")\n",
    "    print(f\"Total parameters in the model: {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KAN on Multivariate Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Irrigation System (small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.37e-01 | test_loss: 4.64e-02 | reg: 0.00e+00 | :   3%| | 3/100 [00:00<00:09, 10.02it"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 9.87e-02 | test_loss: 4.56e-02 | reg: 1.46e+01 | : 100%|â–ˆ| 100/100 [00:07<00:00, 14.01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Training completed and model saved as 'trained_irrigation_model1.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation1.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"moisture\", \"temp\"]\n",
    "TARGET = \"pump\"\n",
    "\n",
    "# Split the data into inputs and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the model\n",
    "model = kan.KAN(width=[2, 3, 3, 1], grid=5, k=3, seed=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit({'train_input': train_X, 'train_label': train_y, 'test_input': test_X, 'test_label': test_y},\n",
    "          opt=\"LBFGS\", steps=100)\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_irrigation_model1.pth')\n",
    "print(\"Training completed and model saved as 'trained_irrigation_model1.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load the model architecture and state dictionary\n",
    "model = kan.KAN(width=[2, 3, 3, 1], grid=5, k=3, seed=0)\n",
    "model.load_state_dict(torch.load('trained_irrigation_model1.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define a function for prediction\n",
    "def predict_pump(moisture, temp):\n",
    "    # Convert input to tensor\n",
    "    input_tensor = torch.tensor([[moisture, temp]], dtype=torch.float32)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    \n",
    "    # Interpret output as ON or OFF\n",
    "    pump_status = \"OFF\" if output.item() >= 0.5 else \"ON\"\n",
    "    return pump_status\n",
    "\n",
    "# Request user input\n",
    "try:\n",
    "    moisture = float(input(\"Enter soil moisture level: \"))\n",
    "    temp = float(input(\"Enter temperature: \"))\n",
    "    result = predict_pump(moisture, temp)\n",
    "    print(f\"The pump should be: {result}\")\n",
    "except ValueError:\n",
    "    print(\"Please enter valid numerical values for moisture and temperature.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Irrigation System (Large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementing using KAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.08e+00 | test_loss: 1.95e+00 | reg: 0.00e+00 | :   1%| | 10/1000 [00:00<00:21, 45.98"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.81e-01 | test_loss: 4.76e-01 | reg: 2.84e+02 | : 100%|â–ˆ| 1000/1000 [00:16<00:00, 59.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Training completed and model saved as 'trained_irrigation_model2.pth'\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the model\n",
    "model = kan.KAN(width=[len(FEATURES), 4, 4, 1], grid=5, k=3, seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit({'train_input': train_X, 'train_label': train_y, 'test_input': test_X, 'test_label': test_y},\n",
    "          opt=\"Adam\", steps=1000)\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_irrigation_model2.pth')\n",
    "print(\"Training completed and model saved as 'trained_irrigation_model2.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "The pump should be: ON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Define the model architecture and load the trained model\n",
    "model = kan.KAN(width=[8, 4, 4, 1], grid=5, k=3, seed=42)\n",
    "model.load_state_dict(torch.load('trained_irrigation_model2.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Prediction function\n",
    "def predict_pump(soil_moisture, temp, air_temp, rainfall, air_humidity, wind_speed, wind_gust, soil_humidity):\n",
    "    # Convert input to tensor\n",
    "    input_data = [soil_moisture, temp, air_temp, rainfall, air_humidity, wind_speed, wind_gust, soil_humidity]\n",
    "    input_tensor = torch.tensor([input_data], dtype=torch.float32)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    \n",
    "    # Interpret output as ON or OFF\n",
    "    pump_status = \"ON\" if output.item() >= 0.5 else \"OFF\"\n",
    "    return pump_status\n",
    "\n",
    "# Request user input\n",
    "try:\n",
    "    soil_moisture = float(input(\"Enter Soil Moisture: \"))\n",
    "    temp = float(input(\"Enter Soil Temperature: \"))\n",
    "    air_temp = float(input(\"Enter Air Temperature (C): \"))\n",
    "    rainfall = float(input(\"Enter Rainfall: \"))\n",
    "    air_humidity = float(input(\"Enter Air Humidity (%): \"))\n",
    "    wind_speed = float(input(\"Enter Wind Speed (Km/h): \"))\n",
    "    wind_gust = float(input(\"Enter Wind Gust (Km/h): \"))\n",
    "    soil_humidity = float(input(\"Enter Soil Humidity: \"))\n",
    "    \n",
    "    # Predict and print the result\n",
    "    result = predict_pump(soil_moisture, temp, air_temp, rainfall, air_humidity, wind_speed, wind_gust, soil_humidity)\n",
    "    print(f\"The pump should be: {result}\")\n",
    "except ValueError:\n",
    "    print(\"Please enter valid numerical values for all inputs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Model Accuracy on Test Set: 67.27%\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load the dataset and preprocess it\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Define features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "test_X, test_y = X_tensor[train_size:], y_tensor[train_size:]\n",
    "\n",
    "# Load the trained model\n",
    "model = kan.KAN(width=[len(FEATURES), 4, 4, 1], grid=5, k=3, seed=42)\n",
    "model.load_state_dict(torch.load('trained_irrigation_model2.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_X)\n",
    "\n",
    "# Convert predictions to binary values (0 or 1) using a threshold of 0.5\n",
    "predicted_labels = (predictions >= 0.5).float()\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predicted_labels == test_y).sum().item()\n",
    "accuracy = correct_predictions / len(test_y)\n",
    "\n",
    "print(f\"Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison with MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.6856\n",
      "Epoch [200/1000], Loss: 0.6554\n",
      "Epoch [300/1000], Loss: 0.6332\n",
      "Epoch [400/1000], Loss: 0.6150\n",
      "Epoch [500/1000], Loss: 0.5960\n",
      "Epoch [600/1000], Loss: 0.5855\n",
      "Epoch [700/1000], Loss: 0.5804\n",
      "Epoch [800/1000], Loss: 0.5774\n",
      "Epoch [900/1000], Loss: 0.5760\n",
      "Epoch [1000/1000], Loss: 0.5751\n",
      "Training completed and model saved as 'trained_mlp_irrigation_model2mlp.pth'\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 4)\n",
    "        self.hidden2 = nn.Linear(4, 4)\n",
    "        self.output = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))  # Sigmoid to output probability\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = MLP(input_size=len(FEATURES))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(train_X)\n",
    "    loss = criterion(outputs, train_y)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_mlp_irrigation_model2mlp.pth')\n",
    "print(\"Training completed and model saved as 'trained_mlp_irrigation_model2mlp.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Accuracy (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Set: 72.73%\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the MLP model (same structure as in training script)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 4)\n",
    "        self.hidden2 = nn.Linear(4, 4)\n",
    "        self.output = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))  # Sigmoid to output probability\n",
    "        return x\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "test_X, test_y = X_tensor[train_size:], y_tensor[train_size:]\n",
    "\n",
    "# Load the trained MLP model\n",
    "model = MLP(input_size=len(FEATURES))\n",
    "model.load_state_dict(torch.load('trained_mlp_irrigation_model2mlp.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_X)\n",
    "\n",
    "# Convert predictions to binary values (0 or 1) using a threshold of 0.5\n",
    "predicted_labels = (predictions >= 0.5).float()\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predicted_labels == test_y).sum().item()\n",
    "accuracy = correct_predictions / len(test_y)\n",
    "\n",
    "print(f\"Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
