{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pykan Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pykan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KANs on Univariate Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Number Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from kan import KAN\n",
    "from kan.utils import create_dataset, ex_round\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('datasets/numsquares.csv')\n",
    "x = torch.tensor(df[['number']].values, dtype=torch.float32)\n",
    "y = torch.tensor(df[['square']].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Step 2: Prepare the dataset\n",
    "dataset = {\n",
    "    'train_input': x,\n",
    "    'train_label': y,\n",
    "    'test_input': x,  # Using the same data for testing, for simplicity\n",
    "    'test_label': y\n",
    "}\n",
    "\n",
    "# Step 3: Initialize the KAN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KAN(width=[1, 5, 1], grid=3, k=3, seed=42, device=device)\n",
    "\n",
    "# Step 4: Plot initial KAN state (Optional)\n",
    "model(dataset['train_input'])\n",
    "model.plot()\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(dataset, opt=\"LBFGS\", steps=100, lamb=0.001)\n",
    "\n",
    "# Step 6: Plot trained KAN state (Optional)\n",
    "model.plot()\n",
    "\n",
    "# Step 7: Extract and print the symbolic formula\n",
    "symbolic_formula = ex_round(model.symbolic_formula()[0][0], 4)\n",
    "print(\"Learned symbolic formula:\", symbolic_formula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted square of 8 is approximately 64.00260162353516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.00260162353516"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_square(number):\n",
    "    # Convert the input to a tensor and ensure it's on the same device\n",
    "    input_tensor = torch.tensor([[number]], dtype=torch.float32).to(device)\n",
    "\n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():  # No need for gradients during inference\n",
    "        output_tensor = model(input_tensor)\n",
    "\n",
    "    # Extract the predicted value and print it\n",
    "    predicted_square = output_tensor.item()\n",
    "    print(f\"The predicted square of {number} is approximately {predicted_square}\")\n",
    "    return predicted_square\n",
    "\n",
    "\n",
    "predict_square(int(input(\"Input Number:\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Univariate Time Series (Daily Minimum Temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementation with KAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 7.50e-02 | test_loss: 1.02e-01 | reg: 1.63e+01 | : 100%|â–ˆ| 100/100 [00:38<00:00,  2.57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "time_series_data = pd.read_csv('datasets/dailymintemp.csv', parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "# Feature Engineering\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "# Convert labels to Float type\n",
    "train_labels = torch.tensor(train_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Normalize labels and window values\n",
    "norm_max = train_labels.max()\n",
    "train_labels /= norm_max\n",
    "test_labels /= norm_max\n",
    "for window_column in window_columns:\n",
    "    selected_data[window_column] /= norm_max.item()\n",
    "\n",
    "input_columns = BASE_INPUT_COLUMNS + window_columns\n",
    "train_input = torch.tensor(np.array([train_raw[in_col].values for in_col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "test_input = torch.tensor(np.array([test_raw[in_col].values for in_col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "# Training model with sliding window data\n",
    "model = kan.KAN(width=[len(input_columns), 3, 3, 1], grid=10, k=3, seed=0)\n",
    "model.fit({'train_input': train_input, 'train_label': train_labels, 'test_input': test_input, 'test_label': test_labels}, opt=\"LBFGS\", steps=100)\n",
    "\n",
    "# Save the model for inference\n",
    "torch.save(model.state_dict(), 'trained_kan_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Array: [0.08333333333333333, 0.16129032258064516, 0.9772727272727273, 0.8636363636363636, 0.8409090909090909]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data similar to your original dataset\n",
    "data = {\n",
    "    \"Date\": pd.date_range(start=\"2022-01-01\", periods=10, freq=\"D\"),\n",
    "    \"Daily minimum temperatures\": [20.0, 18.5, 19.0, 21.5, 20.0, 17.5, 18.0, 20.5, 22.0, 19.5]\n",
    "}\n",
    "time_series_data = pd.DataFrame(data)\n",
    "\n",
    "# Normalize columns\n",
    "time_series_data[\"month normalized\"] = time_series_data[\"Date\"].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[\"Date\"].dt.day / time_series_data[\"Date\"].dt.days_in_month\n",
    "\n",
    "# Add past temperatures (recent values)\n",
    "window_len = 3\n",
    "for i in range(1, window_len + 1):\n",
    "    time_series_data[f\"old val -{i}\"] = time_series_data[\"Daily minimum temperatures\"].shift(i)\n",
    "\n",
    "# Define a function to get the normalized input array for a specific date\n",
    "def get_normalized_array(date, df):\n",
    "    # Filter for the specific date\n",
    "    row = df[df[\"Date\"] == date].iloc[0]\n",
    "\n",
    "    # Normalize recent temperatures by the maximum temperature in the dataset (for consistency)\n",
    "    norm_max = df[\"Daily minimum temperatures\"].max()\n",
    "\n",
    "    # Prepare the array\n",
    "    normalized_array = [\n",
    "        row[\"month normalized\"],\n",
    "        row[\"day normalized\"],\n",
    "        row[f\"old val -1\"] / norm_max if pd.notna(row[f\"old val -1\"]) else None,\n",
    "        row[f\"old val -2\"] / norm_max if pd.notna(row[f\"old val -2\"]) else None,\n",
    "        row[f\"old val -3\"] / norm_max if pd.notna(row[f\"old val -3\"]) else None\n",
    "    ]\n",
    "    \n",
    "    return normalized_array\n",
    "\n",
    "# Example usage\n",
    "date_input = pd.Timestamp(\"2022-01-05\")\n",
    "normalized_array = get_normalized_array(date_input, time_series_data)\n",
    "print(\"Normalized Array:\", normalized_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Predicted Daily Minimum Temperature: 8.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Define model architecture (ensure it matches the architecture used during training)\n",
    "model = kan.KAN(width=[5, 3, 3, 1], grid=10, k=3, seed=0)  # Adjust `width` based on the input configuration during training\n",
    "\n",
    "# Load the state dictionary from the saved file\n",
    "model.load_state_dict(torch.load('trained_kan_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Prediction function\n",
    "def predict_daily_min_temp(input_data, norm_max):\n",
    "    # Convert the input data to a tensor with float32 dtype\n",
    "    input_tensor = torch.tensor([input_data], dtype=torch.float32)\n",
    "    \n",
    "    # Make prediction without computing gradients\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(input_tensor)\n",
    "    \n",
    "    # Denormalize the output to get the actual temperature value\n",
    "    predicted_temp = output_tensor.item() * norm_max\n",
    "    return predicted_temp\n",
    "\n",
    "# Example normalized input for prediction\n",
    "# Format: [month normalized, day normalized, old val -1, old val -2, old val -3]\n",
    "sample_input = [0.5, 0.15, 0.7, 0.65, 0.6]  # Replace with actual input values\n",
    "norm_max = 20.0  # Replace with the actual max value used for label normalization during training\n",
    "\n",
    "# Run inference\n",
    "predicted_temp = predict_daily_min_temp(sample_input, norm_max)\n",
    "print(f\"Predicted Daily Minimum Temperature: {predicted_temp:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Mean Absolute Error (MAE): 53.3042\n",
      "Root Mean Squared Error (RMSE): 56.3500\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the dataset and preprocess it (similar to the training script)\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "data_file = 'datasets/dailymintemp.csv'\n",
    "time_series_data = pd.read_csv(data_file, parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "# Feature Engineering\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "# Prepare test input and labels\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "norm_max = test_labels.max()\n",
    "test_labels /= norm_max\n",
    "test_input = torch.tensor(np.array([test_raw[col].values for col in BASE_INPUT_COLUMNS + window_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "# Load the trained model\n",
    "model = kan.KAN(width=[len(BASE_INPUT_COLUMNS + window_columns), 3, 3, 1], grid=10, k=3, seed=0)\n",
    "model.load_state_dict(torch.load('trained_kan_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_input) * norm_max  # Denormalize predictions\n",
    "    test_labels = test_labels * norm_max  # Denormalize true labels\n",
    "\n",
    "# Convert predictions and test labels to numpy arrays\n",
    "predictions = predictions.numpy().squeeze()\n",
    "test_labels = test_labels.numpy().squeeze()\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(test_labels, predictions)\n",
    "rmse = mean_squared_error(test_labels, predictions, squared=False)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementation with MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0219\n",
      "Epoch [20/100], Loss: 0.0208\n",
      "Epoch [30/100], Loss: 0.0202\n",
      "Epoch [40/100], Loss: 0.0195\n",
      "Epoch [50/100], Loss: 0.0186\n",
      "Epoch [60/100], Loss: 0.0176\n",
      "Epoch [70/100], Loss: 0.0165\n",
      "Epoch [80/100], Loss: 0.0154\n",
      "Epoch [90/100], Loss: 0.0145\n",
      "Epoch [100/100], Loss: 0.0137\n",
      "Training completed and model saved as 'trained_mlp_univariate_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "time_series_data = pd.read_csv('datasets/dailymintemp.csv', parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "# Feature Engineering\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "# Convert labels to Float type\n",
    "train_labels = torch.tensor(train_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Normalize labels and window values\n",
    "norm_max = train_labels.max()\n",
    "train_labels /= norm_max\n",
    "test_labels /= norm_max\n",
    "for window_column in window_columns:\n",
    "    selected_data[window_column] /= norm_max.item()\n",
    "\n",
    "# Prepare training and test data tensors\n",
    "input_columns = BASE_INPUT_COLUMNS + window_columns\n",
    "train_input = torch.tensor(np.array([train_raw[col].values for col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "test_input = torch.tensor(np.array([test_raw[col].values for col in input_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 3)\n",
    "        self.hidden2 = nn.Linear(3, 3)\n",
    "        self.output = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = MLP(input_size=len(input_columns))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(train_input)\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_mlp_univariate_model.pth')\n",
    "print(\"Training completed and model saved as 'trained_mlp_univariate_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Check (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 92.0017\n",
      "Root Mean Squared Error (RMSE): 96.5915\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Define the MLP model (same structure as in training script)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 3)\n",
    "        self.hidden2 = nn.Linear(3, 3)\n",
    "        self.output = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Load the dataset and preprocess it (same as training script)\n",
    "DATASET_DATE_COLUMN = 'Date'\n",
    "data_file = 'datasets/dailymintemp.csv'\n",
    "time_series_data = pd.read_csv(data_file, parse_dates=[DATASET_DATE_COLUMN])\n",
    "time_series_data[\"month normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.month / 12\n",
    "time_series_data[\"day normalized\"] = time_series_data[DATASET_DATE_COLUMN].dt.day / time_series_data[DATASET_DATE_COLUMN].dt.days_in_month\n",
    "time_series_data[\"Daily minimum temperatures\"] = pd.to_numeric(time_series_data[\"Daily minimum temperatures\"], errors='coerce')\n",
    "time_series_data = time_series_data[time_series_data[\"Daily minimum temperatures\"].notnull()]\n",
    "\n",
    "# Feature Engineering\n",
    "WINDOW_LEN = 3\n",
    "TRAIN_TEST_RATIO = 0.2\n",
    "LABEL_COLUMN = \"Daily minimum temperatures\"\n",
    "BASE_INPUT_COLUMNS = [\"month normalized\", \"day normalized\"]\n",
    "\n",
    "selected_data = time_series_data[BASE_INPUT_COLUMNS + [LABEL_COLUMN]].copy()\n",
    "window_columns = []\n",
    "for i in range(WINDOW_LEN):\n",
    "    window_col_name = f'old val -{i+1}'\n",
    "    window_columns.append(window_col_name)\n",
    "    selected_data[window_col_name] = selected_data[LABEL_COLUMN].shift(i+1)\n",
    "\n",
    "selected_data = selected_data[WINDOW_LEN:]\n",
    "train_size = int(len(selected_data) * (1 - TRAIN_TEST_RATIO))\n",
    "train_raw, test_raw = selected_data[:train_size], selected_data[train_size:]\n",
    "\n",
    "# Prepare test input and labels\n",
    "test_labels = torch.tensor(test_raw[LABEL_COLUMN].values, dtype=torch.float32).unsqueeze(-1)\n",
    "norm_max = test_labels.max()\n",
    "test_labels /= norm_max\n",
    "test_input = torch.tensor(np.array([test_raw[col].values for col in BASE_INPUT_COLUMNS + window_columns]), dtype=torch.float32).transpose(0, 1)\n",
    "\n",
    "# Load the trained MLP model\n",
    "model = MLP(input_size=len(BASE_INPUT_COLUMNS + window_columns))\n",
    "model.load_state_dict(torch.load('trained_mlp_univariate_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_input) * norm_max  # Denormalize predictions\n",
    "    test_labels = test_labels * norm_max  # Denormalize true labels\n",
    "\n",
    "# Convert predictions and test labels to numpy arrays\n",
    "predictions = predictions.numpy().squeeze()\n",
    "test_labels = test_labels.numpy().squeeze()\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(test_labels, predictions)\n",
    "rmse = mean_squared_error(test_labels, predictions, squared=False)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KAN on Multivariate Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Irrigation System (small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.37e-01 | test_loss: 4.64e-02 | reg: 0.00e+00 | :   3%| | 3/100 [00:00<00:09, 10.02it"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 9.87e-02 | test_loss: 4.56e-02 | reg: 1.46e+01 | : 100%|â–ˆ| 100/100 [00:07<00:00, 14.01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Training completed and model saved as 'trained_irrigation_model1.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation1.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"moisture\", \"temp\"]\n",
    "TARGET = \"pump\"\n",
    "\n",
    "# Split the data into inputs and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the model\n",
    "model = kan.KAN(width=[2, 3, 3, 1], grid=5, k=3, seed=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit({'train_input': train_X, 'train_label': train_y, 'test_input': test_X, 'test_label': test_y},\n",
    "          opt=\"LBFGS\", steps=100)\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_irrigation_model1.pth')\n",
    "print(\"Training completed and model saved as 'trained_irrigation_model1.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load the model architecture and state dictionary\n",
    "model = kan.KAN(width=[2, 3, 3, 1], grid=5, k=3, seed=0)\n",
    "model.load_state_dict(torch.load('trained_irrigation_model1.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define a function for prediction\n",
    "def predict_pump(moisture, temp):\n",
    "    # Convert input to tensor\n",
    "    input_tensor = torch.tensor([[moisture, temp]], dtype=torch.float32)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    \n",
    "    # Interpret output as ON or OFF\n",
    "    pump_status = \"OFF\" if output.item() >= 0.5 else \"ON\"\n",
    "    return pump_status\n",
    "\n",
    "# Request user input\n",
    "try:\n",
    "    moisture = float(input(\"Enter soil moisture level: \"))\n",
    "    temp = float(input(\"Enter temperature: \"))\n",
    "    result = predict_pump(moisture, temp)\n",
    "    print(f\"The pump should be: {result}\")\n",
    "except ValueError:\n",
    "    print(\"Please enter valid numerical values for moisture and temperature.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Irrigation System (Large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementing using KAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.08e+00 | test_loss: 1.95e+00 | reg: 0.00e+00 | :   1%| | 10/1000 [00:00<00:21, 45.98"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.81e-01 | test_loss: 4.76e-01 | reg: 2.84e+02 | : 100%|â–ˆ| 1000/1000 [00:16<00:00, 59.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Training completed and model saved as 'trained_irrigation_model2.pth'\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the model\n",
    "model = kan.KAN(width=[len(FEATURES), 4, 4, 1], grid=5, k=3, seed=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit({'train_input': train_X, 'train_label': train_y, 'test_input': test_X, 'test_label': test_y},\n",
    "          opt=\"Adam\", steps=1000)\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_irrigation_model2.pth')\n",
    "print(\"Training completed and model saved as 'trained_irrigation_model2.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "The pump should be: ON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:798: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:808: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:809: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kan/MultKAN.py:810: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Define the model architecture and load the trained model\n",
    "model = kan.KAN(width=[8, 4, 4, 1], grid=5, k=3, seed=42)\n",
    "model.load_state_dict(torch.load('trained_irrigation_model2.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Prediction function\n",
    "def predict_pump(soil_moisture, temp, air_temp, rainfall, air_humidity, wind_speed, wind_gust, soil_humidity):\n",
    "    # Convert input to tensor\n",
    "    input_data = [soil_moisture, temp, air_temp, rainfall, air_humidity, wind_speed, wind_gust, soil_humidity]\n",
    "    input_tensor = torch.tensor([input_data], dtype=torch.float32)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    \n",
    "    # Interpret output as ON or OFF\n",
    "    pump_status = \"ON\" if output.item() >= 0.5 else \"OFF\"\n",
    "    return pump_status\n",
    "\n",
    "# Request user input\n",
    "try:\n",
    "    soil_moisture = float(input(\"Enter Soil Moisture: \"))\n",
    "    temp = float(input(\"Enter Soil Temperature: \"))\n",
    "    air_temp = float(input(\"Enter Air Temperature (C): \"))\n",
    "    rainfall = float(input(\"Enter Rainfall: \"))\n",
    "    air_humidity = float(input(\"Enter Air Humidity (%): \"))\n",
    "    wind_speed = float(input(\"Enter Wind Speed (Km/h): \"))\n",
    "    wind_gust = float(input(\"Enter Wind Gust (Km/h): \"))\n",
    "    soil_humidity = float(input(\"Enter Soil Humidity: \"))\n",
    "    \n",
    "    # Predict and print the result\n",
    "    result = predict_pump(soil_moisture, temp, air_temp, rainfall, air_humidity, wind_speed, wind_gust, soil_humidity)\n",
    "    print(f\"The pump should be: {result}\")\n",
    "except ValueError:\n",
    "    print(\"Please enter valid numerical values for all inputs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "Model Accuracy on Test Set: 67.27%\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "# Load the dataset and preprocess it\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Define features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "test_X, test_y = X_tensor[train_size:], y_tensor[train_size:]\n",
    "\n",
    "# Load the trained model\n",
    "model = kan.KAN(width=[len(FEATURES), 4, 4, 1], grid=5, k=3, seed=42)\n",
    "model.load_state_dict(torch.load('trained_irrigation_model2.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_X)\n",
    "\n",
    "# Convert predictions to binary values (0 or 1) using a threshold of 0.5\n",
    "predicted_labels = (predictions >= 0.5).float()\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predicted_labels == test_y).sum().item()\n",
    "accuracy = correct_predictions / len(test_y)\n",
    "\n",
    "print(f\"Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison with MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.6856\n",
      "Epoch [200/1000], Loss: 0.6554\n",
      "Epoch [300/1000], Loss: 0.6332\n",
      "Epoch [400/1000], Loss: 0.6150\n",
      "Epoch [500/1000], Loss: 0.5960\n",
      "Epoch [600/1000], Loss: 0.5855\n",
      "Epoch [700/1000], Loss: 0.5804\n",
      "Epoch [800/1000], Loss: 0.5774\n",
      "Epoch [900/1000], Loss: 0.5760\n",
      "Epoch [1000/1000], Loss: 0.5751\n",
      "Training completed and model saved as 'trained_mlp_irrigation_model2mlp.pth'\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # Convert target to tensor with float32\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "train_X, test_X = X_tensor[:train_size], X_tensor[train_size:]\n",
    "train_y, test_y = y_tensor[:train_size], y_tensor[train_size:]\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 4)\n",
    "        self.hidden2 = nn.Linear(4, 4)\n",
    "        self.output = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))  # Sigmoid to output probability\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = MLP(input_size=len(FEATURES))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(train_X)\n",
    "    loss = criterion(outputs, train_y)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_mlp_irrigation_model2mlp.pth')\n",
    "print(\"Training completed and model saved as 'trained_mlp_irrigation_model2mlp.pth'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Accuracy (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Set: 72.73%\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the MLP model (same structure as in training script)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 4)\n",
    "        self.hidden2 = nn.Linear(4, 4)\n",
    "        self.output = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))  # Sigmoid to output probability\n",
    "        return x\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "DATASET_FILE = 'datasets/irrigation2.csv'\n",
    "data = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "# Select input features and target variable\n",
    "FEATURES = [\"Soil Moisture\", \"Temperature\", \"Air temperature (C)\", \"rainfall\", \"Air humidity (%)\", \"Wind speed (Km/h)\", \"Wind gust (Km/h)\", \" Soil Humidity\"]\n",
    "TARGET = \"Status\"\n",
    "\n",
    "# Convert target variable to binary: ON = 1, OFF = 0\n",
    "data[TARGET] = data[TARGET].apply(lambda x: 1 if x == \"ON\" else 0)\n",
    "\n",
    "# Extract features and target\n",
    "X = data[FEATURES].values\n",
    "y = data[TARGET].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# Split into train and test sets\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "train_size = int(len(X_tensor) * TRAIN_TEST_RATIO)\n",
    "test_X, test_y = X_tensor[train_size:], y_tensor[train_size:]\n",
    "\n",
    "# Load the trained MLP model\n",
    "model = MLP(input_size=len(FEATURES))\n",
    "model.load_state_dict(torch.load('trained_mlp_irrigation_model2mlp.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Make predictions on the test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_X)\n",
    "\n",
    "# Convert predictions to binary values (0 or 1) using a threshold of 0.5\n",
    "predicted_labels = (predictions >= 0.5).float()\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predicted_labels == test_y).sum().item()\n",
    "accuracy = correct_predictions / len(test_y)\n",
    "\n",
    "print(f\"Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
